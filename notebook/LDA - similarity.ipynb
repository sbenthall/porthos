{
 "metadata": {
  "name": "LDA - similarity"
 }, 
 "nbformat": 2, 
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "from __future__ import print_function, division", 
      "import sys", 
      "sys.path.append(\"../\")", 
      "import cPickle", 
      "import gensim", 
      "import re", 
      "import text_processing", 
      "reload(text_processing)", 
      "stopwords=text_processing.stopwords", 
      "from text_processing import to_bow", 
      "from zlib import decompress", 
      "from matplotlib.ticker import MultipleLocator, FormatStrFormatter"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 10
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "i2w, w2i = cPickle.load(open('../data/i2w-w2i.db','r'))", 
      "html=cPickle.load(open('../data/html.db', 'r'))"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 34
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "tweets=cPickle.load(open('../data/tweets+.db', 'r'))"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 35
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "def to_nbow(text):", 
      "    return [[w2i[x[0]], x[1]] for x in to_bow(text, w2i).items() if x[0] not in stopwords]"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 72
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "def jacc(x, y):", 
      "    if len(x)==0 or len(y)==0:", 
      "        return 0", 
      "    return len(x & y)/len(x)"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 73
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 38
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 40
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 41
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "hist(ham, alpha=0.5, normed=True, color='b')", 
      "hist(spam, alpha=0.5, normed=True, color='r')"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 37
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "candidates=set() #set of interesting htmls to consider", 
      "for key in html:", 
      "    for comp in html[key]:", 
      "        bag=to_bow(decompress(comp), w2i)", 
      "        if len(bag)>0:", 
      "            if key not in candidates:", 
      "                candidates.add(key)"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 4
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "random.seed(0)", 
      "pcandidates=random.permutation(list(candidates))"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 31
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "corpus=[]", 
      "for key in pcandidates[:10000]:", 
      "    for comp in html[key]:", 
      "        corpus.append(to_nbow(decompress(comp)))"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 48
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "model=gensim.models.ldamodel.LdaModel(corpus, id2word=i2w, num_topics=100)"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 49
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 6
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "tweets.keys()[:10]"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 56
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 87
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "b=model[to_nbow(decompress(html['94041daa43fc3dca1a3582119b74b4a7'][0]))]"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 86
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "def cosine(x, y):", 
      "    if len(x) == 0 or len(y) == 0:", 
      "        return 0", 
      "    ", 
      "    Nx=0", 
      "    Ny=0", 
      "    num=0", 
      "    j=0", 
      "    i=0", 
      "    while i < len(x):", 
      "        if j < len(y):", 
      "            if x[i][0]==y[j][0]:", 
      "                num += x[i][1]*y[j][1]", 
      "                Nx+=x[i][1]**2", 
      "                Ny+=y[j][1]**2", 
      "                i+=1", 
      "                j+=1", 
      "                continue", 
      "            if x[i][0]<y[j][0]:", 
      "                Nx+=x[i][1]**2", 
      "                i+=1", 
      "                continue", 
      "            if x[i][0]>y[j][0]:", 
      "                Ny+=y[j][1]**2", 
      "                j+=1", 
      "                continue", 
      "        else:", 
      "            Nx+=x[i][1]**2", 
      "            i+=1", 
      "    while j < len(y):", 
      "        Ny+=y[j][1]**2", 
      "        j+=1", 
      "    return num/sqrt(Nx*Ny)"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 67
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "k=0", 
      "spam=[]", 
      "ham=[]", 
      "for key in tweets:", 
      "    if tweets[key]['lang_infered']=='en':", 
      "        if key in html:", 
      "            tw=to_nbow(tweets[key]['text_clean'])", 
      "            if len(tw)<1:", 
      "                continue", 
      "            if len(html[key])>0:", 
      "                    ht=to_nbow(decompress(html[key][0]))", 
      "                    if len(ht)<1:", 
      "                        continue", 
      "            else:", 
      "                continue", 
      "            d=[]", 
      "            for i in range(50):", 
      "                twv=model[tw]", 
      "                htv=model[ht]", 
      "                d.append(cosine(twv, htv))", 
      "            if tweets[key]['label']==1:", 
      "                spam.append(mean(d))", 
      "            else:", 
      "                ham.append(mean(d))", 
      "            if k>1000:", 
      "                break", 
      "            k+=1", 
      "        else:", 
      "            continue"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 212
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "hist(ham, alpha=0.5, bins=50, normed=True, cumulative=False, histtype='stepfilled', label='Ham ('+str(len(ham))+')', color='b')", 
      "hist(spam, alpha=0.5, bins=50, normed=True, cumulative=False, histtype='stepfilled', label='Spam ('+str(len(spam))+')', color='r')", 
      "legend(loc=2)", 
      "title(\"CDF of cosine similarity for spam and ham\")", 
      "xlabel(\"cosine similarity\")", 
      "ylabel(\"proportion\")"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 228
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "for key in tweets:", 
      "    if tweets[key]['lang_infered']=='en':", 
      "        if tweets[key]['label']==0:", 
      "            print(tweets[key]['text_original'])"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 219
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "save('gammas-spam-ham', full_matrix)", 
      "save('labels', labels)"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 61
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "[i2w[x[0]] for x in corpus[0]]"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 24
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "model_all.show_topics(25)"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 18
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 2
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "def auc(h_scores, s_scores):", 
      "    j=0", 
      "    i=0", 
      "    neg=0", 
      "    pos=0", 
      "    while i < len(h_scores):", 
      "        while j < len(s_scores) and s_scores[j] < h_scores[i]:", 
      "            j += 1", 
      "        neg += len(s_scores) - j", 
      "        pos += j", 
      "        i += 1", 
      "    return pos/(neg+pos)"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 45
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "def similarities(models, sim_func, average=1):", 
      "    dist=[dict() for i in range(len(models))]", 
      "    n=0", 
      "    for key in tweets:", 
      "        n+=1", 
      "        if tweets[key]['lang_infered'] == 'en':", 
      "            ", 
      "            tw=to_nbow(tweets[key]['text_clean'])", 
      "            if len(tw)<1:", 
      "                #print(\"no data in tweet\")", 
      "                continue", 
      "            ", 
      "            for comp in html[key]:", 
      "                ht = to_nbow(decompress(comp))", 
      "                if len(ht)>0:", 
      "                    if key not in dist[0]:", 
      "                        sim = [[] for i in range(len(models))]", 
      "                        for i in range(len(models)):", 
      "                            dist[i][key]=[]", 
      "                    ", 
      "                    for i in range(len(models)):", 
      "                        sim[i].append(mean([sim_func(models[i][tw], models[i][ht]) for k in range(average)]))", 
      "            ", 
      "            if key in dist[0]:", 
      "                for i in range(len(models)):", 
      "                    dist[i][key]=[min(sim[i]), max(sim[i]), mean(sim[i])]", 
      "        ", 
      "        if n%1000 == 0:", 
      "            print(\"%1.1f%%\"%(100*n/218000), end=' ')", 
      "    return dist", 
      "", 
      "def separate(dist, i):", 
      "    spam=[]", 
      "    ham=[]", 
      "    for key in dist:", 
      "        if len(dist[key])>0:", 
      "            if tweets[key]['label'] == 1:", 
      "                spam.append(dist[key][i])", 
      "            else:", 
      "                ham.append(dist[key][i])", 
      "    return ham, spam"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 190
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "#model5=gensim.models.lsimodel.LsiModel.load(\"../LDAmodel-5t.pkl\")", 
      "#model10=gensim.models.lsimodel.LsiModel.load(\"../LDAmodel-10t.pkl\")", 
      "#model20=gensim.models.lsimodel.LsiModel.load(\"../LDAmodel-20t.pkl\")", 
      "#model40=gensim.models.lsimodel.LsiModel.load(\"../LDAmodel-40t.pkl\")", 
      "#model80=gensim.models.lsimodel.LsiModel.load(\"../LDAmodel-80t.pkl\")", 
      "#model160=gensim.models.lsimodel.LsiModel.load(\"../LDAmodel-160t.pkl\")", 
      "model=gensim.models.tfidfmodel.TfidfModel.load(\"../TFIDFmodel.pkl\")", 
      "", 
      "#dist = similarities([model], cosine, average=1)", 
      "for i in range(3):", 
      "    ham, spam = separate(dist[0], i)", 
      "    print(auc(sorted(ham), sorted(spam)), end=' ')"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "0.168479895801 0.16895393273"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        " 0.16896610377"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        " "
       ]
      }
     ], 
     "prompt_number": 210
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "cPickle.dump(dist, open('similarities-tfidf.db', 'w'))"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 211
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "ham, spam = separate(dist[0], 1)", 
      "ax=subplot(111)", 
      "plot(sorted(ham), arange(len(ham))/len(ham), '--.', color='b', alpha=0.5, label='ham')", 
      "plot(sorted(spam), arange(len(spam))/len(spam), '--.' ,color='r', alpha=0.5, label='spam')", 
      "minorLocator = MultipleLocator(0.1)", 
      "ax.xaxis.set_minor_locator(minorLocator)", 
      "ax.yaxis.set_minor_locator(minorLocator)", 
      "grid(which='major', axis='both')", 
      "grid(which='minor', axis='both')", 
      "xlabel('similarity')", 
      "ylabel('proportion')", 
      "legend(loc=4)", 
      "xlim(0,1)", 
      "savefig(\"cosine_tfidf_dist_max.eps\", bbox_inches='tight')"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 212
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 86
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": "&nbsp;"
    }
   ]
  }
 ]
}